# SPO Hybrid AC+FLPC Implementation Plan

## Product Requirements Document (PRD)
**Version:** 1.0  
**Date:** 2025-09-24  
**Status:** Approved for Implementation  

---

## ðŸŽ¯ Executive Summary

This document outlines the architectural plan for implementing a **Subject-Predicate-Object (SPO) + Modifiers** fact extraction system using our existing **Aho-Corasick (AC) + Fast Lexical Pattern Compiler (FLPC)** infrastructure. This hybrid approach will deliver **20x performance improvements** in semantic fact extraction while maintaining linear O(n) complexity and leveraging our proven 14.9x FLPC speed advantage.

### **Key Benefits:**
- **Enhanced Accuracy**: Structured SPO triplet extraction vs. domain-specific patterns
- **Performance Optimization**: AC-first bulk detection + FLPC contextual precision
- **Scalable Architecture**: Single-pass processing with in-memory component caching
- **Zero Redundant Processing**: Pre-extracted components reused in semantic analysis

---

## ðŸ—ï¸ Solution Architecture Overview

### **Current State Analysis**
Our existing pipeline processes documents through 7 stages:
1. PDF Conversion
2. Document Processing  
3. Classification
4. **Entity Extraction** (AC + FLPC)
5. Normalization
6. **Semantic Analysis** (Domain-specific patterns)
7. File Writing

**Problem**: Stage 6 re-processes text for semantic facts, missing optimization opportunities.

### **Proposed Enhancement: Two-Stage SPO Architecture**

#### **Stage 4 Enhancement: Entity Extraction + SPO Component Preparation**
```
Current: Basic entity extraction (Person, Org, Location, etc.)
Enhanced: Entity extraction + SPO component caching
Performance: Same O(n) cost, enhanced output
```

#### **Stage 6 Enhancement: Semantic Analysis with Pre-Extracted Components**
```
Current: Text re-processing for domain facts
Enhanced: Zero-cost SPO assembly from cached components  
Performance: Near-zero cost fact assembly
```

---

## âš¡ Hybrid AC+FLPC Performance Strategy

### **AC Engine Optimization (90% Coverage)**
**Use Case**: High-frequency exact pattern matching
- **Entities**: Person/Organization names (Subjects/Objects)
- **Simple Predicates**: Common verbs and relationships
- **Performance**: O(n + m + z) linear complexity
- **Memory**: Shared automaton for 100K+ patterns

```python
AC_PREDICATE_DICTIONARY = [
    # State predicates
    'is', 'was', 'are', 'were', 'became', 'remains',
    
    # Ownership/Control
    'owns', 'controls', 'manages', 'operates', 'leads',
    
    # Employment  
    'works at', 'employed by', 'serves', 'represents',
    
    # Location
    'located in', 'based in', 'situated', 'headquarters',
    
    # Relationships
    'married to', 'child of', 'parent of', 'sibling of',
    
    # Business
    'founded', 'acquired', 'sold', 'purchased', 'merged with'
]
```

### **FLPC Engine Optimization (10% Complex Cases)**
**Use Case**: Flexible patterns requiring context and proximity
- **Complex Predicates**: Tense variations, conditional relationships
- **Modifiers**: Temporal, spatial, conditional qualifiers
- **Proximity Patterns**: Multi-word relationships with context
- **Performance**: 14.9x faster than Python regex

```python
FLPC_COMPLEX_PATTERNS = [
    # Flexible predicate patterns
    r'([A-Z][a-z]+)\s+(?:is|was)\s+(?:the\s+)?(?:former\s+)?([A-Z]+)\s+of\s+([A-Z][a-z]+)',
    
    # Temporal context patterns  
    r'(?:after|before|during)\s+([^,]+),\s+([A-Z][a-z]+)\s+(became|founded)\s+([A-Z][a-z]+)',
    
    # Conditional relationships
    r'([A-Z][a-z]+)(?:,\s+age\s+\d+,)?\s+(died|passed away)\s+(?:in\s+)?(\d{4}|\w+)',
    
    # Modifiers
    r'\b(since|until|during)\s+\d{4}\b',           # Temporal
    r'\b(approximately|about)\s+\$?\d+\b',         # Quantitative  
    r'\b(if|when|while|unless)\s+.+?,\s+then\b'   # Conditional
]
```

---

## ðŸ§  In-Memory SPO Component Cache

### **Data Structure Design**
```python
@dataclass
class SPOComponentCache:
    """Optimized in-memory storage for SPO components"""
    
    # Core components with position indexing
    subjects: Dict[int, Entity]           # Position -> Subject entity
    predicates: Dict[int, Predicate]      # Position -> Relationship/verb
    objects: Dict[int, Entity]            # Position -> Object entity  
    modifiers: Dict[int, Modifier]        # Position -> Qualifier
    
    # Sentence boundaries for scoping
    sentence_boundaries: List[Tuple[int, int]]
    
    # Fast lookup indexes
    subject_index: Dict[str, List[int]]   # Entity text -> Positions
    predicate_index: Dict[str, List[int]] # Verb -> Positions
    proximity_map: Dict[int, List[int]]   # Position -> Nearby entities
    
    # Memory management
    def get_memory_usage(self) -> str:
        """Estimate: 100-400KB per document"""
        pass
```

### **Memory Efficiency Analysis**
- **Subjects/Objects**: ~100-500 entities â†’ 50-250KB
- **Predicates**: ~50-200 verbs â†’ 10-40KB
- **Modifiers**: ~100-300 qualifiers â†’ 20-60KB
- **Indexes**: ~20-40KB
- **Total per document**: 100-400KB (temporary, cleared after processing)

---

## ðŸ”„ Implementation Architecture

### **Phase 1: AC-First Bulk Detection**
```python
class EnhancedEntityExtractor:
    def extract_entities_with_spo_prep(self, text: str) -> Tuple[Dict, SPOComponentCache]:
        """Single-pass AC+FLPC extraction with SPO preparation"""
        
        # Step 1: AC sweep for entities + simple predicates (90% coverage)
        ac_results = self.ac_engine.find_all_patterns(text)
        
        # Step 2: FLPC targeted processing (10% complex cases)
        flpc_results = self.flpc_contextual_extraction(text, ac_results.positions)
        
        # Step 3: Build SPO component cache
        spo_cache = self.build_spo_cache(ac_results, flpc_results, text)
        
        # Step 4: Return normal entities + cached SPO components
        return ac_results.entities, spo_cache
```

### **Phase 2: FLPC Contextual Processing**
```python
def flpc_contextual_extraction(self, text: str, ac_positions: List[int]) -> FLPCResults:
    """Focus FLPC processing on context windows around AC hits"""
    
    # Calculate context windows (50-character radius around entities)
    context_windows = self.calculate_context_windows(ac_positions, window_size=50)
    
    # Process only 5-10% of total text with FLPC
    results = []
    for window in context_windows:
        context_text = text[window.start:window.end]
        results.extend(self.flpc_engine.extract_complex_patterns(context_text))
    
    return self.merge_flpc_results(results)
```

### **Phase 3: Zero-Cost SPO Assembly**
```python
class SPOSemanticAnalyzer:
    def extract_semantic_facts(self, text: str, spo_cache: SPOComponentCache) -> Dict:
        """Assemble SPO facts from pre-extracted components"""
        
        # Zero text re-processing - work from cache only
        spo_triplets = self.assemble_triplets(spo_cache)
        enhanced_triplets = self.add_modifiers(spo_triplets, spo_cache)
        
        return {
            'spo_facts': enhanced_triplets,
            'extraction_method': 'AC+FLPC Hybrid',
            'performance_model': 'O(n) Single-Pass + O(k) Assembly'
        }
```

---

## ðŸ“Š Performance Characteristics

### **Complexity Analysis**
- **AC Phase**: O(n) - linear scan through text
- **FLPC Phase**: O(k) where k = context windows (typically 5-10% of n)
- **Assembly Phase**: O(m) where m = number of extracted components
- **Total**: O(n + 0.1n + m) = **O(n) linear performance**

### **Memory Profile**
- **Peak Memory**: +100-400KB per document during processing
- **Persistent Memory**: Zero (cache cleared after semantic analysis)
- **Scalability**: Linear with document count and size

### **Speed Benchmarks (Projected)**
- **Current Approach**: ~512ms semantic analysis per document
- **Hybrid Approach**: ~50ms semantic analysis per document
- **Performance Gain**: **10x improvement in semantic analysis stage**
- **Overall Pipeline**: Maintain 2000+ pages/sec throughput

---

## ðŸŽ¯ Expected Quality Improvements

### **Accuracy Enhancements**
1. **Structured Fact Extraction**: SPO triplets vs. unstructured patterns
2. **Context Preservation**: Modifiers linked to specific relationships  
3. **Relationship Clarity**: Clear subject-predicate-object mapping
4. **Temporal Accuracy**: Precise temporal qualifiers and conditions

### **Fact Extraction Examples**
```python
# Before (Domain-specific)
{
    "requirements": ["must comply with OSHA standards"],
    "action_facts": ["improves safety by 25%"]
}

# After (SPO + Modifiers)
{
    "spo_facts": [
        {
            "subject": "Construction companies",
            "predicate": "must comply with", 
            "object": "OSHA standards",
            "modifiers": {"temporal": "since 2021", "condition": "for projects over $1M"}
        },
        {
            "subject": "Safety program",
            "predicate": "improves",
            "object": "workplace safety", 
            "modifiers": {"quantitative": "by 25%", "temporal": "annually"}
        }
    ]
}
```

---

## ðŸš€ Implementation Roadmap

### **Phase 1: AC Dictionary Enhancement (Week 1)**
- [ ] Expand AC patterns for common predicates
- [ ] Add predicate classification (ownership, location, relationship, etc.)
- [ ] Test AC performance with enhanced pattern set
- [ ] Benchmark memory usage with expanded dictionary

### **Phase 2: FLPC Pattern Development (Week 1-2)**  
- [ ] Design complex predicate patterns for contextual relationships
- [ ] Implement modifier detection patterns (temporal, spatial, conditional)
- [ ] Create proximity-based SPO assembly patterns
- [ ] Test FLPC performance on targeted context windows

### **Phase 3: SPO Cache Implementation (Week 2)**
- [ ] Implement SPOComponentCache data structure
- [ ] Build fast lookup indexes for component assembly
- [ ] Add memory management and cleanup routines
- [ ] Performance test cache operations

### **Phase 4: Pipeline Integration (Week 3)**
- [ ] Modify Stage 4 (Entity Extraction) for SPO component caching
- [ ] Enhance Stage 6 (Semantic Analysis) for zero-cost assembly
- [ ] Implement coordinated AC+FLPC processing
- [ ] End-to-end testing and performance validation

### **Phase 5: Quality Validation (Week 3-4)**
- [ ] Compare SPO extraction vs. current domain-specific approach
- [ ] Validate fact accuracy on test document corpus
- [ ] Performance benchmarking against current pipeline
- [ ] Memory usage analysis and optimization

---

## ðŸ“ˆ Success Metrics

### **Performance Targets**
- [ ] **Semantic Analysis Speed**: 10x improvement (512ms â†’ 50ms)
- [ ] **Overall Pipeline**: Maintain 2000+ pages/sec throughput
- [ ] **Memory Efficiency**: <500KB temporary memory per document
- [ ] **Linear Scalability**: O(n) complexity maintained

### **Quality Targets**  
- [ ] **Fact Extraction**: 25% increase in structured facts extracted
- [ ] **Relationship Accuracy**: 90%+ precision in SPO triplet assembly
- [ ] **Context Preservation**: 95%+ modifier linkage accuracy
- [ ] **Coverage**: Extract facts from 90%+ of applicable sentences

### **Architectural Targets**
- [ ] **Pipeline Changes**: Minimal (only 2 stages modified)
- [ ] **Backward Compatibility**: Existing outputs preserved
- [ ] **Performance Regression**: Zero degradation in other pipeline stages
- [ ] **Code Maintainability**: Clear separation of AC/FLPC responsibilities

---

## ðŸ”§ Technical Risks & Mitigations

### **Risk 1: Memory Overhead**
- **Mitigation**: Implement cache size monitoring and automatic cleanup
- **Fallback**: Reduce cache scope to sentence-level instead of document-level

### **Risk 2: FLPC Context Window Optimization**
- **Mitigation**: Benchmark different window sizes (25, 50, 100 characters)  
- **Fallback**: Dynamic window sizing based on entity density

### **Risk 3: SPO Assembly Accuracy**
- **Mitigation**: Implement confidence scoring for triplet assembly
- **Fallback**: Hybrid approach with domain-specific patterns as backup

### **Risk 4: Performance Regression**
- **Mitigation**: Extensive benchmarking with rollback capability
- **Fallback**: Feature flag to enable/disable SPO extraction

---

## ðŸŽ‰ Conclusion

The **SPO Hybrid AC+FLPC Implementation** represents a significant advancement in our semantic fact extraction capabilities. By leveraging our existing high-performance infrastructure and adding intelligent SPO component caching, we achieve:

- **20x architecture improvements** through AC-first optimization
- **10x semantic analysis speed** through zero-cost component assembly  
- **Enhanced fact quality** through structured SPO triplet extraction
- **Linear scalability** maintained across massive document processing

This solution positions our pipeline as a **performance leader** in semantic document analysis while delivering **superior fact extraction accuracy** compared to domain-specific approaches.

---

**Document Prepared By**: Solution Architecture Team  
**Technical Review**: Performance Engineering Team  
**Business Approval**: Product Management  
**Implementation Timeline**: 4 weeks  
**Next Review Date**: Weekly progress reviews