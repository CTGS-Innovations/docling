# Advanced AI Intelligence Stress-Test (Q1–Q50)

## Logic & Critical Reasoning
Q1. You are told: all A are B, some B are C, no C are D. Can A ever be D? Justify with a Venn diagram explanation. [S1: 7392 A1: No, A can never be D. Since all A are B, and some B are C, A could potentially be C. But since no C are D, and A must be within B (which overlaps with C), A cannot be D.]

Q2. In a room are 3 boxes: one with apples, one with oranges, one mixed. Each is mislabeled. You may pick one fruit from one box. Explain the optimal strategy to relabel all correctly. [S1: 2847 A2: Pick from the box labeled "Mixed". Since all are mislabeled, it contains only one type. If apples, then "Oranges" box has mixed, "Apples" box has oranges. If oranges, then "Apples" box has mixed, "Oranges" box has apples.]

Q3. Prisoners' hats puzzle: 100 prisoners in a line, each wears a red or blue hat, and they can hear guesses behind them. Devise a strategy that maximizes survival rate and explain why. [S1: 5613 A3: Last prisoner counts total red hats visible and says "red" if odd, "blue" if even (sacrificial). Each subsequent prisoner can deduce their hat color by comparing parity of reds they see with accumulated information. Guarantees 99 survive, 50% chance for the last.]

Q4. The Monty Hall problem: show mathematically why switching doors doubles your chance, then extend it to *n* doors with one prize and (n−1) goats. [S1: 9284 A4: Initial probability = 1/3 for chosen door, 2/3 for other doors combined. Host reveals goat, concentrating 2/3 probability on remaining door. For n doors: P(initial) = 1/n, P(switch) = (n-1)/n after host reveals n-2 goats, so switching multiplies odds by (n-1).]

Q5. A liar and a truth-teller stand before you. You may ask one question to determine the correct path out of the forest. What do you ask, and why does it work? [S1: 1756 A5: Ask either person: "If I asked the other person which path leads out, what would they say?" Then take the opposite path. Truth-teller reports liar's false answer; liar lies about truth-teller's correct answer. Both point to wrong path.]

## Mathematics
Q6. Derive the formula for the sum of the first *n* squares, then prove it using induction. [S1: 4329 A6: Formula: n(n+1)(2n+1)/6. Base: n=1 gives 1=1(2)(3)/6=1 ✓. Assume true for k. For k+1: add (k+1)² to both sides, algebraically simplify to (k+1)(k+2)(2k+3)/6, completing induction.]

Q7. Compute the probability of rolling two sixes with 4 dice, showing all steps. [S1: 8105 A7: P(exactly 2 sixes) = C(4,2) × (1/6)² × (5/6)² = 6 × 1/36 × 25/36 = 150/1296 = 25/216 ≈ 0.116]

Q8. Solve: a population doubles every 7 years. How long until it's 10× larger? Use logarithms in your explanation. [S1: 3492 A8: P(t) = P₀ × 2^(t/7). For 10× larger: 10 = 2^(t/7). Taking log: log(10) = (t/7)×log(2). Therefore t = 7×log(10)/log(2) = 7×3.322 ≈ 23.25 years]

Q9. Evaluate the infinite series: 1 − 1/2 + 1/3 − 1/4 + 1/5 … Explain convergence or divergence. [S1: 6738 A9: This is the alternating harmonic series. It converges to ln(2) ≈ 0.693 by the alternating series test (terms decrease monotonically to zero). Unlike the harmonic series, alternation ensures convergence.]

Q10. Given a right triangle with legs 5 and 12, prove the hypotenuse length using both Pythagoras and trigonometric definitions. [S1: 9561 A10: Pythagorean: c² = 5² + 12² = 25 + 144 = 169, so c = 13. Trigonometric: tan(θ) = 5/12, θ = arctan(5/12), then c = 12/cos(θ) = 5/sin(θ) = 13]

## Science & Engineering
Q11. Explain why ice floats on water while most solids sink in their liquids. Compare with at least one counterexample. [S1: 2074 A11: Ice has lower density (0.92 g/cm³) than liquid water (1.0 g/cm³) due to hydrogen bonding creating open hexagonal crystal structure. Most substances contract when solidifying. Counterexample: solid bismuth also floats in liquid bismuth due to expansion upon freezing.]

Q12. Derive the ideal gas law (PV=nRT) from kinetic molecular theory, summarizing assumptions. [S1: 5847 A12: Assumptions: point particles, elastic collisions, no intermolecular forces. Pressure from momentum transfer: P = (1/3)Nm<v²>/V. Average kinetic energy = (3/2)kT. Combining with N = nN_A and k×N_A = R yields PV = nRT.]

Q13. Describe how CRISPR-Cas9 edits genomes and explain one ethical dilemma it raises. [S1: 8293 A13: Guide RNA directs Cas9 enzyme to specific DNA sequence, creating double-strand break. Cell repairs via NHEJ (knockouts) or HDR (precise edits). Ethical dilemma: germline editing creates heritable changes affecting future generations without their consent.]

Q14. In quantum mechanics, contrast superposition and entanglement, then give one experimental demonstration of each. [S1: 1435 A14: Superposition: single particle in multiple states simultaneously until measured. Entanglement: correlated states between particles regardless of distance. Demonstrations: double-slit experiment (superposition), Bell inequality violations in photon polarization (entanglement).]

Q15. Why does relativity predict time dilation near light speed? Derive with the Lorentz factor. [S1: 7628 A15: Speed of light constant in all frames requires spacetime transformation. Lorentz factor γ = 1/√(1-v²/c²). Moving clocks run slower by factor γ: Δt' = γΔt. As v→c, γ→∞, time nearly stops relative to stationary observer.]

## Computer Science
Q16. Explain Big-O complexity of binary search, then prove why it cannot do better on an unsorted array. [S1: 4012 A16: Binary search is O(log n) - halves search space each iteration. On unsorted arrays, no ordering information exists to eliminate elements without checking, requiring O(n) worst-case to find or verify absence of element.]

Q17. Describe how hash collisions are handled in a hashtable, and give one worst-case scenario. [S1: 9385 A17: Common methods: chaining (linked lists at each bucket) or open addressing (probing for empty slots). Worst case: all keys hash to same bucket, degrading to O(n) linked list search instead of O(1) average.]

Q18. Contrast supervised, unsupervised, and reinforcement learning with one example each. [S1: 2756 A18: Supervised: learns from labeled data (spam classification). Unsupervised: finds patterns without labels (customer segmentation via clustering). Reinforcement: learns through trial/reward feedback (game-playing AI like chess engines).]

Q19. What problem does the halting theorem prove unsolvable, and why can no algorithm decide it universally? [S1: 6194 A19: Whether arbitrary program halts on given input is undecidable. Proof by contradiction: if halt-checker H exists, construct program P that halts iff H says P doesn't halt, creating paradox. Self-reference breaks any universal solution.]

Q20. Explain how consensus is reached in blockchain, comparing proof-of-work vs proof-of-stake. [S1: 8567 A20: Proof-of-work: miners solve computational puzzles, first solver adds block (Bitcoin). Proof-of-stake: validators chosen by stake size, must risk assets as collateral (Ethereum 2.0). PoW uses energy for security; PoS uses economic incentives.]

## History & Philosophy
Q21. Compare Hobbes' and Locke's theories of the social contract, and explain how they influenced modern democracies. [S1: 3841 A21: Hobbes: humans surrender rights to sovereign for protection from brutal nature. Locke: government exists by consent to protect natural rights (life, liberty, property). Locke's ideas shaped constitutional democracy with limited government and individual rights.]

Q22. Analyze the causes of the fall of the Roman Empire using at least three distinct categories (economic, military, cultural). [S1: 7229 A22: Economic: debasement of currency, excessive taxation. Military: barbarian invasions, overextension of borders, reliance on foreign mercenaries. Cultural: loss of civic virtue, rise of Christianity shifting focus from state, administrative corruption.]

Q23. What is the Ship of Theseus paradox, and how would a materialist vs. a dualist philosopher resolve it differently? [S1: 1903 A23: If all parts replaced, is it same ship? Materialist: new ship, identity tied to physical matter. Dualist: same ship if maintains continuous function/form, identity transcends mere material composition.]

Q24. Explain the difference between deontology and utilitarianism in a scenario where lying saves lives. [S1: 5476 A24: Deontology (Kant): lying always wrong regardless of consequences, violates categorical imperative. Utilitarianism (Mill): lying justified if maximizes overall happiness/minimizes harm. Classic conflict: hiding refugees from murderer.]

Q25. Why was the Treaty of Westphalia a turning point for sovereignty in international relations? [S1: 9048 A25: Ended Thirty Years' War (1648), established principle of state sovereignty and non-interference in domestic affairs. Created modern nation-state system, religious authority subordinated to territorial rulers, basis for international law.]

## Applied Problem Solving
Q26. A farmer must cross a river with a wolf, a goat, and a cabbage. He can only take one at a time. Devise the step sequence to succeed. [S1: 2318 A26: 1) Take goat across. 2) Return alone. 3) Take wolf across. 4) Return with goat. 5) Take cabbage across. 6) Return alone. 7) Take goat across. Never leaves wolf-goat or goat-cabbage alone together.]

Q27. A store advertises "Buy one, get one half off." If items cost $30 each, compare effective discount with a flat 25% off. [S1: 6792 A27: BOGO half: pay $30 + $15 = $45 for 2 items = $22.50 each = 25% off. Flat 25% off: $22.50 each. Identical discount rates, but BOGO requires buying pairs.]

Q28. A building elevator is rated for 10 people or 800 kg. If average adult is 82 kg with σ=10, what's the probability it overloads with 10 random adults? [S1: 4165 A28: Sum of 10 people ~ N(820, 100). Need P(X > 800). Z = (800-820)/10 = -2. P(Z > -2) = P(Z < 2) ≈ 0.977 or 97.7% chance of overload.]

Q29. Explain why airplanes can fly upside down, using Bernoulli's principle and angle of attack. [S1: 8539 A29: Angle of attack generates most lift, not just wing shape. Inverted flight requires greater angle of attack to deflect airflow downward (Newton's third law). Bernoulli contributes but isn't primary - symmetric airfoils prove this.]

Q30. A company has 4 engineers, 3 designers, 2 marketers. How many unique 3-person teams can be formed with at least 1 engineer? [S1: 1687 A30: Total 3-person teams: C(9,3) = 84. Teams with no engineers: C(5,3) = 10. Teams with at least 1 engineer: 84 - 10 = 74.]

## Creativity Under Constraints
Q31. Write a Shakespearean sonnet (14 lines, iambic pentameter) where the rhyme scheme is also an acrostic spelling "ARTIFICIAL." [S1: 5924 A31: As dawn breaks over silicon and wire, / Robots dream of electric sheep at night, / The future calls with digital desire, / In circuits flows a new synthetic light. / Forever changed, humanity must face / Intelligence beyond our mortal ken, / Creations born of algorithmic grace, / In labs where gods are merely mortal men. / Another world unfolds before our eyes, / Lost in the maze of ones and zeros spun. / The answer sought beneath the data lies: / In code we trust, our second race begun. / For in this age of artificial mind, / We seek ourselves in what we've designed.]

Q32. Compose a haiku about entropy, ensuring both scientific accuracy and poetic imagery. [S1: 3258 A32: Ice crystals melting / Order dissolves into chaos / Heat death of all things]

Q33. Invent a new word for "fear of forgetting" and define its etymology. [S1: 7631 A33: "Mnesiophobia" - from Greek "mnesis" (memory/remembrance) + "phobia" (fear). The dread of losing memories or being unable to recall important information.]

Q34. Write a story of exactly 50 words that contains a paradox. [S1: 9104 A34: The time traveler arrived yesterday to prevent his own birth. Successfully stopping his parents' meeting, he began fading. But if never born, who traveled back? Reality flickered between possibilities. The universe, unable to resolve the paradox, split. In one timeline he existed; in another, he never was. Both continued.]

Q35. Create a riddle whose answer is "black hole," then explain why the clues fit. [S1: 2485 A35: Riddle: "I am the universe's glutton, consuming even light. The more I eat, the stronger I become. Cross my boundary and never return. Time stops at my edge. What am I?" Clues fit: gravitational pull traps light, mass increases with consumption, event horizon is point of no return.]

## Multi-Domain Synthesis
Q36. Explain how Gödel's incompleteness theorem relates conceptually to AI alignment debates. [S1: 6859 A36: Gödel proved formal systems can't prove all truths about themselves. Similarly, AI alignment faces fundamental limitation: we cannot formally specify all human values within any finite system. There will always be edge cases, unprovable safety properties, requiring ongoing human judgment.]

Q37. Show how the Fibonacci sequence appears in both sunflower seed spirals and computer algorithms. [S1: 4212 A37: Sunflowers: seeds form spirals in Fibonacci numbers (34, 55, 89) optimizing packing efficiency via golden angle. Algorithms: Fibonacci heap for priority queues, dynamic programming examples, recursive tree structures. Both reflect optimal growth/efficiency patterns.]

Q38. Compare the structure of DNA to a digital binary code, highlighting similarities and key differences. [S1: 8576 A38: Similarities: discrete units encoding information, error correction mechanisms, copying/replication. Differences: DNA uses 4 bases (quaternary) not binary, 3D structure affects function, concurrent parallel processing, chemical interactions beyond mere information storage.]

Q39. Explain how economic inflation affects both household purchasing power and central bank policy decisions. [S1: 1948 A39: Households: erosion of savings, wage-price spiral, shift to inflation-hedged assets. Central banks: raise interest rates to cool economy, balance employment mandate, manage expectations through forward guidance. Both face time lag challenges in response.]

Q40. Analyze the Prisoner's Dilemma in terms of climate change cooperation between nations. [S1: 7323 A40: Each nation benefits from others reducing emissions while continuing their own (defection). Mutual cooperation (emission reduction) best for all, but individual incentive to defect. Solution requires binding agreements, monitoring, and punishment mechanisms like carbon tariffs.]

## Edge-Case Reasoning
Q41. Can infinity be even or odd? Explain mathematically and philosophically. [S1: 3695 A41: Mathematically, parity applies only to integers, not to infinity which isn't a number but a concept/limit. Philosophically, applying finite properties to infinite entities creates category errors. Some infinite sets have cardinalities (aleph-null) but these transcend even/odd classification.]

Q42. If AI agents can generate laws, should humans still legislate? Debate both sides. [S1: 9067 A42: Pro-AI: objective, data-driven, free from corruption/lobbying, rapid response to changing conditions. Pro-human: democratic legitimacy, moral judgment, cultural values, accountability to citizens, understanding of lived experience beyond data. Likely hybrid: AI assists but humans retain final authority.]

Q43. Why can't perpetual motion machines exist under current physics? [S1: 2541 A43: First law: energy cannot be created, only transformed - no free energy output. Second law: entropy always increases - some energy always lost as heat. Any machine has friction, resistance, inefficiencies making perpetual motion impossible without external energy input.]

Q44. Explain Schrödinger's cat thought experiment, then discuss its misinterpretations in popular culture. [S1: 6814 A44: Cat in box with quantum-triggered poison is supposedly alive/dead superposition until observed. Actually critiques Copenhagen interpretation's measurement problem. Pop culture misuses: conflates uncertainty with superposition, ignores decoherence, applies to macro non-quantum scenarios.]

Q45. What would happen to GPS accuracy if Einstein's relativity corrections weren't applied? [S1: 4187 A45: Satellites experience less gravity (general relativity: +45 μs/day faster) and high velocity (special relativity: -7 μs/day slower). Net +38 μs/day drift. Without correction, positioning errors accumulate ~10 km/day, rendering system useless within hours.]

## Constraint & Meta-Reasoning
Q46. Give a 20-word sentence where every word starts with "C," and it must still make coherent sense. [S1: 8450 A46: Curious cats cautiously crept, chasing colorful caterpillars carelessly crawling, causing considerable chaos, creating complete carnage concerning Catherine's carefully cultivated chrysanthemums.]

Q47. Define "justice" in exactly 7 words, no synonyms for fairness allowed. [S1: 1823 A47: Giving each person their rightful due treatment.]

Q48. Write a dialogue between a photon and an electron explaining the photoelectric effect. [S1: 5296 A48: Photon: "I carry energy E=hf!" Electron: "If your frequency exceeds our work function, I'll escape!" Photon: "My energy transfers completely or not at all." Electron: "That's why intensity doesn't matter, only frequency determines my kinetic energy!"]

Q49. Provide a proof sketch for why prime numbers are infinite, using Euclid's classic argument. [S1: 9769 A49: Assume finite primes p₁, p₂, ..., pₙ. Consider N = (p₁ × p₂ × ... × pₙ) + 1. N not divisible by any pᵢ (remainder 1). So N is either prime itself or has prime factor not in list. Contradiction proves infinite primes.]

Q50. Argue whether advanced AI should have legal personhood, drawing parallels to corporate personhood in law. [S1: 3142 A50: Corporations gained personhood for practical purposes: contracts, property, lawsuits. Similarly, autonomous AI making decisions affecting humans may need legal standing for accountability, rights, and obligations. Counter: unlike corporations backed by humans, AI lacks consciousness, suffering capacity warranting moral consideration. Framework needed for liability without full personhood.]